{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c32d9721",
   "metadata": {},
   "source": [
    "BandAid Beta Buddy - Options for No Stitching of Pre/Post\n",
    "=====\n",
    "\n",
    "An Automatic Beta Cell Analysis Pipeline \n",
    "---\n",
    "\n",
    "Stitches Pre and Post & Only Segments Max Values of Pre and Post Images\n",
    "---\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "#### Written with equal contibution by: Anne Alsup *anne.alsup@mavs.uta.edu* & Kelli Fowlds *kelli.fowlds@mavs.uta.edu*.\n",
    "\n",
    "Major compontents of the Cellpose script was written by Pradeep Rajasekhar. The [Cellpose GitHub](https://github.com/MouseLand/cellpose) along with the original [GoogleColab](https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/Cellpose_cell_segmentation_2D_prediction_only.ipynb) by Pradeep are linked. \n",
    "\n",
    "Please read through all instructions given in each step cell. This a customizable pipeline, but the given format must be followed!\n",
    "\n",
    "If you run into any issues, please let us know in our [BetaBuddy GitHub](https://github.com/jacobluber/BetaBuddy)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6513d7b",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1. nd2 to TIFF conversion\n",
    "<hr>\n",
    "\n",
    "1. The BBB_Cellpose directory will be emptied before each run. **Save or move any images you want to keep before running this step.**\n",
    "\n",
    "\n",
    "2. If you already have TIFF file: \n",
    "    + Comment out (add a *#* before the line) the two lines that begin with *!./bftools/bfconvert* in **Cell1**.\n",
    "    \n",
    "\n",
    "3. If you already have TIFF files you will have to: \n",
    "    + Comment out (add a *#* before the line) the two lines that begin with *!./bftools/bfconvert* in **Cell1**.\n",
    "    \n",
    "    \n",
    "    \n",
    "4. **If you have a different file type, please use the *!./btftools/bfcovert* to convert your file to TIFF**\n",
    "\n",
    "\n",
    "5. Change the arguements for bftools\n",
    "    + There are arguements for Pre and Post images along with their respective DAPI stain.\n",
    "    + Change the *./1V_Ca_Spike_Post.nd2* and/or *./DAPI_Post.nd2* to your ND2 file name(s). Keep the **./** before your file name as this lets the program know you file is located in the current directory.\n",
    "    + Change the *1VSpiking.tif* and/or *1VDAPI.tif* name(s) to what you want your TIFF to be named. This arguement does *not* need the **./**.\n",
    "\n",
    "\n",
    "*Note: Your filenames cannot have any spaces when using a LINUX OS. Replacing spaces with '_' is common practice.* <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b230245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell1\n",
    "############################################################################################\n",
    "################################### Follow this format: ####################################\n",
    "############# !./bftools/bfconvert -overwrite ./FILENAME.nd2 NEWFILENAME.tif ###############\n",
    "############################################################################################\n",
    "\n",
    "!./bftools/bfconvert -overwrite ./DAPI_Pre.nd2 1VDAPIPre.tif \n",
    "!./bftools/bfconvert -overwrite ./1V_Ca_Spike_Pre.nd2 1VPre.tif\n",
    "# !./bftools/bfconvert -overwrite ./DAPI_Post.nd2 1VDAPIPost.tif \n",
    "# !./bftools/bfconvert -overwrite ./1V_Ca_Spike_Post.nd2 1VPost.tif\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Emptying the CellPoseImg directory that will be the output directory for the merged image\n",
    "imgsave_dir = \"./BBB_Cellpose\"\n",
    "if not os.path.exists(imgsave_dir):\n",
    "    print(\"No BBB_Cellpose directory found. Creating a new one.\")\n",
    "    os.mkdir(imgsave_dir)\n",
    "else:\n",
    "  print(\"Existing BBB_Cellpose directory found. Deleting it.\")\n",
    "  shutil.rmtree(imgsave_dir)\n",
    "  os.mkdir(imgsave_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ebe1c",
   "metadata": {},
   "source": [
    "##  Step 2. Merge single DAPI stain with max fluorescent image </h2>\n",
    "<hr>\n",
    "\n",
    "\n",
    "\n",
    "* The input argument for this step will follow this format **'/my/path/end/with/slash/ 1VDAPIPre 1VDAPIPost'**\n",
    "    + Every arguement is seperated with a space. Follow the steps below for all 3 arguements.\n",
    "    + *Do **NOT** add the image format (.tif) to the end of the file name*\n",
    "\n",
    "* Comment out the following if you don't have two image sets:\n",
    "    + *impost = imread(dir_path+'/1VPost.tif')* \n",
    "    + *B = np.max(impost,axis=0)* \n",
    "    + *cv2.imwrite(dir_path+\"/BBB_Post.png\", B)* \n",
    "\n",
    "1. Your current directory path **ENDING** with a **BACKSLASH** (/my/path/end/with/slash/).\n",
    "2. Arguement for if you are stitching Control and Experimental Images.\n",
    "    + Add ***NoStitch*** if you are **NOT** including two different image sets. Still include a fourth arguement.\n",
    "    + Add ***Stitch*** if you have two image sets (Pre/Post).\n",
    "3. Your *Pre/Control* DAPI image stack name (1VDAPIPre).\n",
    "4. Your *Post/Experimental* DAPI image name (1VDAPIPost).\n",
    "    + *Note the arguement requires **4** inputs*\n",
    "\n",
    "Your Cellpose images will be saved under **./BBB_Cellpose**. The control and experimental images will be saved as \"BBB_*the name of your DAPI image*.tif\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell2\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#get path for image loading\n",
    "dir_path = os.getcwd()\n",
    "print(dir_path)\n",
    "\n",
    "#load stacked original images and mask images\n",
    "###########################################\n",
    "##### CHANGE THE TIF FILE NAMES BELOW #####\n",
    "###########################################\n",
    "\n",
    "imp = imread(dir_path+'/1VPre.tif') #Pre/Control image name! Include the backslash\n",
    "# impost = imread(dir_path+'/1VPost.tif') #Post/Experimental image name! Include the backslash\n",
    "\n",
    "#max and mean pixel value across all frames\n",
    "A = np.max(imp,axis=0)\n",
    "# B = np.max(impost,axis=0)\n",
    "cv2.imwrite(dir_path+\"/BBB_Pre.png\", A)\n",
    "# cv2.imwrite(dir_path+\"/BBB_Post.png\", B)\n",
    "\n",
    "\n",
    "print('The max image for Pre and Post have been saved.')\n",
    "\n",
    "###########################################\n",
    "######### CHANGE THE INPUTS BELOW #########\n",
    "###########################################\n",
    "\n",
    "!./Fiji.app/ImageJ-linux64 --headless -macro ./BBB_DAPIMerge.ijm '/home/BetaBuddy/ NoStitch 1VDAPIPre PlaceHolder'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff82010",
   "metadata": {},
   "source": [
    "Step 3. Automatic cell segmentation with Cellpose \n",
    "----\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839478e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell3\n",
    "# Configuring Cellpose, adding dependencies, and checking GPU access\n",
    "# https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/Cellpose_cell_segmentation_2D_prediction_only.ipynb\n",
    "import numpy as np\n",
    "import time, os, sys, random\n",
    "from urllib.parse import urlparse\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from cellpose import core, utils, models\n",
    "\n",
    "if core.use_gpu()==False: \n",
    "  print(\"You do not have GPU access. Cellpose will run through CPU.\")\n",
    "  use_GPU=False\n",
    "else:\n",
    "  print(\"You have access to the GPU.\")\n",
    "  use_GPU=True\n",
    "\n",
    "!nvidia-smi\n",
    "print(\"All dependencies loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb521f",
   "metadata": {},
   "source": [
    "### Step 3.1: Set parameters for image format, file type, and input directory \n",
    "\n",
    "<hr>\n",
    "\n",
    "#### Widgets will appear in the output after running the cell. It's helpful to run the widget cells using *ctrl+Enter*, so Jupyter doesn't skip to the next cell.\n",
    "\n",
    "#### Note: The button will become dark gray when selected.\n",
    "1. Confirm the input directory is correct. \n",
    "\n",
    "2. Choose a model option \n",
    "    + TN2 and TN3 seem to work best with Beta-cell segmenting. \n",
    "    + Nuclei will work well for images with only DAPI staining. \n",
    "    + *Note: Only nuclei segmentation may not perform well for subsequent tracking and analysis steps.*\n",
    "\n",
    "3. Choose the channel that contains the entire cell to segment. You can reference the images above to find the correct channel.\n",
    "    + *Keep the channel at 0 if you only have one channel.*\n",
    "\n",
    "4. Choose the channel with your DAPI stain. **If you do not have a DAPI stain, keep the channel at 0.**\n",
    "5. Set Cell Probability Threshold  \n",
    "    + Decrease this threshold if your masks are too small or if Cellpose is not detecting enough cells.\n",
    "    + Increase this threshold if Cellpose is detecting too many cells. \n",
    "\n",
    "6. Set Flow Threshold \n",
    "    + Decrease this parameter if Cellpose is not detecting enough cells. \n",
    "    + Increase this parameter if Cellpose is detecting too many cells.      \n",
    " \n",
    "7. Set Diameter\n",
    "     + If you don't konw diameter, leave at 0. \n",
    "     + 70 pixels for 2048x2048 in Beta-cell images at 20X objective. \n",
    "     + Diameter will be in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd877e",
   "metadata": {
    "hide_input": true,
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# Cell4\n",
    "# Creating input widgets\n",
    "\n",
    "###########################################\n",
    "### RUN THIS CELL TO SELECT THE WIDGETS ###\n",
    "###########################################\n",
    "\n",
    "input_dir = os.getcwd() +'/BBB_Cellpose/'\n",
    "print(\"Input directory: \" + input_dir)\n",
    "\n",
    "Model_Choice = widgets.ToggleButtons(\n",
    "    options=['Cytoplasm', 'Cytoplasm2', 'Nuclei', 'TN2','TN3'],\n",
    "    value = 'TN2',\n",
    "    description='Select One', \n",
    ")\n",
    "display(Model_Choice)\n",
    "\n",
    "GPU = widgets.ToggleButtons(\n",
    "    options=['CPU','GPU'],\n",
    "    value = 'GPU',\n",
    "    description = 'Select One')\n",
    "display(GPU)\n",
    "\n",
    "segchan=widgets.Dropdown(\n",
    "    options=['0','1', '2', '3'],\n",
    "    value='1',\n",
    "    description='Cell Channel:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(segchan)\n",
    "\n",
    "\n",
    "qDapi=widgets.Dropdown(\n",
    "    options=['0','1', '2', '3'],\n",
    "    value='2',\n",
    "    description='DAPI Channel:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(qDapi)\n",
    "\n",
    "\n",
    "cellprob=widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=-6, \n",
    "    max=6, \n",
    "    step=1.0, \n",
    "    description='Cell Probability'\n",
    ")\n",
    "display(cellprob)\n",
    "\n",
    "\n",
    "flowthresh = widgets.FloatSlider(\n",
    "    value=0.4,\n",
    "    min=0.1,\n",
    "    max=1.1, \n",
    "    step=0.1, \n",
    "    description='Flow Threshold'\n",
    ")\n",
    "display(flowthresh)\n",
    "\n",
    "\n",
    "diam = widgets.IntText(\n",
    "    value = 70,\n",
    "    min = 0,\n",
    "    max = 200,\n",
    "    step = 1,\n",
    "    description = \"Diameter\")\n",
    "display(diam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell5\n",
    "fname1 = os.listdir(input_dir)\n",
    "fname = [item for item in fname1 if item.endswith(\"tif\")]    \n",
    "\n",
    "imgsave_dir = input_dir\n",
    "\n",
    "\n",
    "#######################################################\n",
    "############ Creating/Emptying Mask folder ############\n",
    "#######################################################\n",
    "\n",
    "save_dir = input_dir+\"Masks/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "else:\n",
    "    print(\"Existing Mask Directory found. Deleting it.\")\n",
    "    shutil.rmtree(save_dir)\n",
    "\n",
    "    \n",
    "if(len(fname)==0):\n",
    "    print(\"Number of images loaded: %d.\" %(len(fname)))\n",
    "    print(\"Cannot read image files. Check if folder has images\")\n",
    "else:\n",
    "    print(\"Number of images loaded: %d.\" %(len(fname)))\n",
    "    \n",
    "#######################################################    \n",
    "### Reading all images and displaying one at random ###\n",
    "#######################################################\n",
    "\n",
    "imgs = []\n",
    "for im in range(len(fname)):\n",
    "    im = skimage.io.imread(imgsave_dir + fname[im])\n",
    "    n_dim=len(im.shape) #shape of image\n",
    "    dim=im.shape #dimensions of image\n",
    "    channel=min(dim) #channel will be dimension with min value usually\n",
    "    channel_position=dim.index(channel)\n",
    "    # If no of dim is 3 and channel is first index, swap channel to last index\n",
    "    if n_dim==3 and channel_position==0: \n",
    "        im=im.transpose(1,2,0)\n",
    "        dim=im.shape\n",
    "    imgs.append(im)\n",
    "print(\"Number of images read: \" + str(len(imgs)))\n",
    "print(\"Example Image:\")\n",
    "random_idx = random.choice(range(len(imgs)))\n",
    "x=imgs[random_idx]\n",
    "n_dim=len(x.shape)\n",
    "file_name=os.path.basename(fname[random_idx])\n",
    "print(file_name+\" has \"+str(n_dim)+\" dimensions/s\")\n",
    "if n_dim==3:\n",
    "    channel_image=x.shape[2]\n",
    "    fig, axs = plt.subplots(1, channel_image,figsize=(12,5))\n",
    "    print(\"Image: %s\" %(file_name))\n",
    "    for channel in range(channel_image):\n",
    "        axs[channel].imshow(x[:,:,channel])\n",
    "        axs[channel].set_title('Channel '+str(channel+1),size=5)\n",
    "        axs[channel].axis('off')\n",
    "    fig.tight_layout()\n",
    "elif n_dim==2:\n",
    "    print(\"One Channel\")\n",
    "    plt.imshow(x)\n",
    "else:\n",
    "    print(\"Channel number invalid or dimensions wrong. Image shape is: \"+str(x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell7\n",
    "import torch\n",
    "print(\"Model choice is: \" + Model_Choice.value)\n",
    "print(\"Segmentation channel is: \" + str(segchan.value))\n",
    "if qDapi.value == 0:\n",
    "    Use_nuclear_channel = False\n",
    "    print(\"No DAPI Channel\")\n",
    "else:\n",
    "    Use_nuclear_channel = True\n",
    "    print(\"DAPI channel is: \" + qDapi.value)\n",
    "    \n",
    "if GPU == 'GPU':\n",
    "    gpuYN = True\n",
    "else:\n",
    "    gpuYN = False\n",
    "        \n",
    "\n",
    "print(\"Cell probability threshold: \" + str(cellprob.value))\n",
    "print(\"Flow threshold: \" + str(flowthresh.value))\n",
    "      \n",
    "model_choice = Model_Choice.value\n",
    "segment_channel = int(segchan.value)\n",
    "nuclear_channel = int(qDapi.value)\n",
    "\n",
    "#diameter = int(diam)\n",
    "\n",
    "if model_choice==\"Cytoplasm\":\n",
    "  model_type=\"cyto\"\n",
    "elif model_choice==\"Cytoplasm2\":\n",
    "  model_type=\"cyto2\"\n",
    "elif model_choice==\"Nuclei\":\n",
    "  model_type=\"nuclei\" \n",
    "elif model_choice==\"TN2\":\n",
    "    model_type=\"TN2\"\n",
    "elif model_choice==\"TN3\":\n",
    "    model_type=\"TN3\"\n",
    "# channels = [cytoplasm, nucleus]\n",
    "\n",
    "########################\n",
    "#### ANNIE FIX THIS ####\n",
    "########################\n",
    "if model_choice not in \"Nucleus\":\n",
    "  if Use_nuclear_channel:\n",
    "    channels=[segment_channel,nuclear_channel]\n",
    "  else:\n",
    "    channels=[segment_channel,nuclear_channel]\n",
    "else: #nucleus\n",
    "  channels=[segment_channel,0]\n",
    "\n",
    "if diam == 0:\n",
    "    diam = None\n",
    "    \n",
    "\n",
    "# DEFINE CELLPOSE MODEL\n",
    "model = models.CellposeModel(gpu=gpuYN, model_type=model_type)\n",
    "print(model)\n",
    "diameter = None\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "flow_threshold=flowthresh.value\n",
    "cellprob_threshold=cellprob.value\n",
    "\n",
    "# You can change the test image here\n",
    "img1=imgs[0]\n",
    "import cv2\n",
    "# masks, flows, styles, diams = model.eval(img1,diameter=diameter,flow_threshold=flow_threshold,cellprob_threshold=cellprob_threshold, channels=channels)\n",
    "# masks = model.eval(img1, channels=[segment_channel, nuclear_channel],\n",
    "#                    diameter=diameter)[0]\n",
    "# masks, flows, styles, diams = model.eval(img1, diameter=diameter, flow_threshold=flow_threshold,cellprob_threshold=cellprob_threshold, channels=channels)\n",
    "masks, flows, styles = model.eval(img1, \n",
    "                                  channels=[segment_channel, nuclear_channel],\n",
    "                                  diameter=diameter,\n",
    "                                  flow_threshold=flow_threshold,\n",
    "                                  cellprob_threshold=cellprob_threshold\n",
    "                                  )\n",
    "# DISPLAY RESULTS\n",
    "from cellpose import plot\n",
    "maski = masks\n",
    "flowi = flows[0]\n",
    "\n",
    "#convert to 8-bit if not so it can display properly in the graph\n",
    "if img1.dtype!='uint8':\n",
    "  img1=img_as_ubyte(img1)\n",
    "\n",
    "fig = plt.figure(figsize=(24,8))\n",
    "plot.show_segmentation(fig, img1, maski, flowi, channels=channels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell8\n",
    "# Save mask images in Masks directory under CellPoseImgs\n",
    "print(\"Save Directory is: \",save_dir)\n",
    "if (not os.path.exists(save_dir)):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "for img_idx in range(len(fname)):\n",
    "    file_name=fname[img_idx]\n",
    "    print(\"\\nSegmenting: \",file_name)\n",
    "#     mask, flow, style, diam = model.eval(imgs[img_idx], diameter=diameter, flow_threshold=flow_threshold,cellprob_threshold=cellprob_threshold, channels=channels)\n",
    "    masks, flows, styles = model.eval(imgs[img_idx], \n",
    "                                  channels=[segment_channel, nuclear_channel],\n",
    "                                  diameter=diameter,\n",
    "                                  flow_threshold=flow_threshold,\n",
    "                                  cellprob_threshold=cellprob_threshold\n",
    "                                  )\n",
    "    # Save name for masks\n",
    "    if file_name.endswith('.tif'):\n",
    "        file_name = re.sub(\".tif\",\"\",file_name)\n",
    "    mask_output_name=save_dir+\"MASK_\"+file_name+\".tif\"\n",
    "    # Save mask as 16-bit in case this has to be used for detecting than 255 objects\n",
    "    # A 16-bit image will look black until opened in software such as ImageJ\n",
    "    # Change \"uint16\" to \"uint8\" if you want the preview to be visible \n",
    "    mask=masks.astype(np.uint16)\n",
    "    skimage.io.imsave(mask_output_name, mask, check_contrast=False)\n",
    " \n",
    "print(\"\\nSegmentation complete and files saved :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5b73b",
   "metadata": {},
   "source": [
    "Step 4. Cell registration and tracking \n",
    "----\n",
    "<hr>\n",
    "\n",
    "1. The first terminal command will merge the mask images with their corresponding orginal beta cell image to begin cell registration. \n",
    "    + **You will need to change the *'/home/BetaBuddy/'* to your current directory**\n",
    "    + 6 Arguments \n",
    "    \n",
    "    1. Directory \n",
    "    2. ***NoStitch*** if you have one image set OR ***Stitch*** if you have two image sets.\n",
    "    3. Target stain image name for control or main image (no .tif for any image names)\n",
    "    4. DAPI stain for control or main image\n",
    "    5. Target stain image name for experimental or any name if you have only one image set.\n",
    "    6. DAPI stain image name for experimental or any name if you have one image set.\n",
    "   \n",
    "    \n",
    "    \n",
    "2. The second terminal command will push our mask/original image stack through the Fiji plugin TrackMate. A few short printouts should show up with a very long log of all the track locations and frames afterwards. \n",
    "</br> \n",
    "\n",
    "\n",
    "\n",
    "### Outputs\n",
    "\n",
    "* An XML titled *MaskMerged.xml* will be saved in the current directory along with the *MaskMerged.tif*. You can load this into Fiji through *Plugins -> Tracking -> Load TrackMate File* and see the calculated tracks. You can also open the *Track* tab and click on TrackIDs to see their location within the TrackMate GUI. \n",
    "* Raw data will be saved in a CSV named \"experimentjup.csv\". \n",
    "\n",
    "*Note: The TrackIDs in the CSV files will be off by one.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98d2a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell9\n",
    "\n",
    "###########################################\n",
    "######### CHANGE THE INPUTS BELOW #########\n",
    "###########################################\n",
    "!./Fiji.app/ImageJ-linux64 --headless -macro ./BBB_MaskMerge.ijm '/home/BetaBuddy/ NoStitch 1VPre 1VDAPIPre 1VPost 1VDAPIPost'\n",
    "!./Fiji.app/ImageJ-linux64 --headless ./BBB_TrackMate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce51c8",
   "metadata": {},
   "source": [
    "Step 5. Background Subtraction \n",
    "----\n",
    "\n",
    "<hr>\n",
    "\n",
    "* Random pixel locations will be chosen and compared to every mask frame to ensure the location is not within a cell. \n",
    "* If the location is not within a cell, the pixel value from every frame will be saved in a csv named \"backgroundsub\". \n",
    "* This will be used in the next step for background subtraction for signal analysis.\n",
    "* Go to the bottom & change file name inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell10\n",
    "\n",
    "import os\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "#get path for image loading\n",
    "dir_path = os.getcwd()\n",
    "print(dir_path)\n",
    "\n",
    "def backgroundsub(img,mask,NewCSV,path,spotnum = 100):\n",
    "    #load stacked original images and mask images\n",
    "    imspike = io.imread(dir_path+img) ##CHANGE NAME\n",
    "    immask = io.imread(dir_path+mask)\n",
    "\n",
    "    # Get dimensions for each image (frames, 900, 900, # of channels)\n",
    "    dims=imspike.shape\n",
    "    dimsm=immask.shape\n",
    "    print(\"Image dimensions: \" + str(dims))\n",
    "\n",
    "    # Create array for pixel values of all 100 spots\n",
    "    x = []\n",
    "    for index in range(0,dims[0]):\n",
    "        x.append([None]*spotnum)\n",
    "\n",
    "    count = 0\n",
    "    # Array to house locations that are not masks\n",
    "    goodlocs=[]\n",
    "    tmpx = []\n",
    "    while count<spotnum:\n",
    "        loc = []\n",
    "        imgval = []\n",
    "        #random pixel location\n",
    "        x1tmp = random.randrange(0,int(len(imspike[1])))\n",
    "        y1tmp = random.randrange(0,int(len(imspike[1])))\n",
    "        imgloc = [int(x1tmp),int(y1tmp)]\n",
    "        tmpx = np.array([None]*int(dims[0]))\n",
    "        for img in range(dims[0]):\n",
    "            #pixel intensity from all three channels\n",
    "            imgval = imspike[img,imgloc[0],imgloc[1]] #8bit\n",
    "            maimgval = immask[img,imgloc[0],imgloc[1]]\n",
    "            # If intensity on mask image is 0, the pixel location is *not* within a cell \n",
    "            if np.all(maimgval==0):\n",
    "                tmpx[img]=imgval \n",
    "            # If intensity on mask image is *not* 0, all temporary variables are emptied   \n",
    "            else:\n",
    "                maimagval = []\n",
    "                imgval = []\n",
    "                imgloc=[]\n",
    "                break\n",
    "        if None in tmpx:\n",
    "          # Empty out temporary array if there are any \"None\"s left\n",
    "          tmpx = []\n",
    "        else: \n",
    "          # Save temporary array into large array will all intensity values  \n",
    "            for do in range(dims[0]):\n",
    "                x[do][count] = tmpx[do]\n",
    "            # Save pixel location  \n",
    "            goodlocs.append(imgloc)\n",
    "            count += 1\n",
    "\n",
    "    # Header row names for csv\n",
    "    heads = []\n",
    "    for namez in range(spotnum):\n",
    "        heads.append('Spot '+ str(namez))\n",
    "\n",
    "    # Saving pixel locations for reference\n",
    "    spotz = []\n",
    "    for locz in range(spotnum):\n",
    "        spotz.append('('+str(goodlocs[locz][1])+'/'+str(goodlocs[locz][0])+')')\n",
    "\n",
    "    print(\"Locations of background subtraction: \" + str(spotz))\n",
    "\n",
    "    # Save intensity values of all 100 pixel locations across all frames\n",
    "    filename = dir_path+\"/BBB_backgroundsub.csv\"\n",
    "    if NewCSV is True:\n",
    "        with open(filename,'w') as csvfile:\n",
    "            csvwriter = csv.writer(csvfile, delimiter = ',',lineterminator='\\r')\n",
    "            csvwrite2 = csv.writer(csvfile, delimiter = ' ',lineterminator='\\r')\n",
    "            csvwriter.writerow(heads)\n",
    "            csvwriter.writerow(spotz)\n",
    "            for i in range(len(x)):\n",
    "                csvwriter.writerow(x[i])\n",
    "    else:\n",
    "        with open(filename,'a') as csvfile: ##Will append to previous csv from pre\n",
    "            csvwriter = csv.writer(csvfile, delimiter = ',',lineterminator='\\r')\n",
    "            csvwrite2 = csv.writer(csvfile, delimiter = ' ',lineterminator='\\r')\n",
    "            for i in range(len(x)):\n",
    "                csvwriter.writerow(x[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "backgroundsub(\"/1VPre.tif\",\"/BBB_1VPre_Mask.tif\",True,dir_path,100) \n",
    "#\"BBB_ + Pre_Name + _Mask.tif\"\n",
    "#\"BBB_ + Post_Name + _Mask.tif\"\n",
    "#backgroundsub('PreImage.tif','/BBB_PreMask.tif',#ofspots,True -> new csv, False -> append to previous csv)\n",
    "\n",
    "#############################################################\n",
    "########## Uncomment below if using two image sets ##########\n",
    "#############################################################\n",
    "\n",
    "# backgroundsub(\"/1VPost.tif\",\"/BBB_1VPost_Mask.tif\", False,dir_path,100)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668ebf4",
   "metadata": {},
   "source": [
    "## Step 6. Statistical Analysis \n",
    "<hr>\n",
    "\n",
    "* We can now run the statistical analysis in an R script! \n",
    "* The cell below should create three figures and a CSV file, named Experimental_Data.csv, you can use in custom analyses. All will be saved in your current directory. \n",
    "* The final CSV file has only tracks that span the full image stack and identifies tracks in the top 20% of signal variance.\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0ce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell11\n",
    "\n",
    "!Rscript Beta_Buddy_Stats_Analysis.R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
